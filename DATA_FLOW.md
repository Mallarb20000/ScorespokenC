# ğŸ“Š ScoreSpoken Data Flow Documentation

## Overview
This document provides a comprehensive breakdown of how data flows through the ScoreSpoken IELTS Speaking Practice Platform, from user interaction to AI analysis and result display.

---

## ğŸ”„ Complete Data Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                             SCORESPOKEN DATA FLOW                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ¯ USER INTERACTION LAYER
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User clicks   â”‚
â”‚ "Start Record"  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Browser asks   â”‚â”€â”€â”€â”€â–¶â”‚ User grants mic  â”‚â”€â”€â”€â”€â–¶â”‚ MediaRecorder   â”‚
â”‚ for mic access  â”‚     â”‚    permission    â”‚     â”‚    starts       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                           â”‚
ğŸ™ï¸ AUDIO CAPTURE LAYER                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Audio chunks    â”‚â—€â”€â”€â”€â”€â”‚ MediaRecorder    â”‚â”€â”€â”€â”€â–¶â”‚ Chunks stored   â”‚
â”‚ collected in    â”‚     â”‚ ondataavailable  â”‚     â”‚ in chunksRef    â”‚
â”‚ real-time       â”‚     â”‚ event fires      â”‚     â”‚ array           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                                                â”‚
          â–¼                                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User clicks     â”‚â”€â”€â”€â”€â–¶â”‚ MediaRecorder    â”‚â”€â”€â”€â”€â–¶â”‚ All chunks      â”‚
â”‚ "Stop Record"   â”‚     â”‚ .stop() called   â”‚     â”‚ combined into   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚ single Blob     â”‚
                                                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸ’¾ DATA PROCESSING LAYER                                   â”‚
                                                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ audioBlob state â”‚â—€â”€â”€â”€â”€â”‚ URL.createObject â”‚â—€â”€â”€â”€â”€â”‚ Blob created    â”‚
â”‚ updated         â”‚     â”‚ URL() creates    â”‚     â”‚ (audio/webm)    â”‚
â”‚                 â”‚     â”‚ playback URL     â”‚     â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                       â”‚                        â”‚
          â–¼                       â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ UI shows Submit â”‚     â”‚ audioUrl state   â”‚     â”‚ Audio ready for â”‚
â”‚ button + Record â”‚     â”‚ updated for      â”‚     â”‚ backend upload  â”‚
â”‚ Again option    â”‚     â”‚ <audio> element  â”‚     â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                                                â”‚
          â–¼                                                â–¼
ğŸŒ HTTP REQUEST LAYER                              
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User clicks     â”‚â”€â”€â”€â”€â–¶â”‚ submitAnswer()   â”‚â”€â”€â”€â”€â–¶â”‚ FormData object â”‚
â”‚ "Submit Answer" â”‚     â”‚ function called  â”‚     â”‚ created with:   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚ - audioBlob     â”‚
                                                 â”‚ - question text â”‚
                                                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                           â”‚
                                                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ setIsProcessing â”‚â—€â”€â”€â”€â”€â”‚ fetch() API call â”‚â—€â”€â”€â”€â”€â”‚ HTTP POST to    â”‚
â”‚ (true) - shows  â”‚     â”‚ to backend with  â”‚     â”‚ /api/analyze-   â”‚
â”‚ loading state   â”‚     â”‚ FormData payload â”‚     â”‚ answer endpoint â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                           â”‚
âš™ï¸ BACKEND PROCESSING LAYER                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Express server  â”‚â—€â”€â”€â”€â”€â”‚ CORS middleware  â”‚â—€â”€â”€â”€â”€â”‚ Request hits    â”‚
â”‚ receives POST   â”‚     â”‚ allows cross-    â”‚     â”‚ Express server  â”‚
â”‚ request         â”‚     â”‚ origin request   â”‚     â”‚ on port 3002    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Multer middle-  â”‚â”€â”€â”€â”€â–¶â”‚ File extracted   â”‚â”€â”€â”€â”€â–¶â”‚ Request body    â”‚
â”‚ ware processes  â”‚     â”‚ from FormData    â”‚     â”‚ parsed for      â”‚
â”‚ multipart data  â”‚     â”‚ into req.file    â”‚     â”‚ question text   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                           â”‚
                                                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Input validationâ”‚â”€â”€â”€â”€â–¶â”‚ Audio converted  â”‚â”€â”€â”€â”€â–¶â”‚ Gemini AI model â”‚
â”‚ ensures file    â”‚     â”‚ to base64 string â”‚     â”‚ initialized     â”‚
â”‚ and question    â”‚     â”‚ for AI API       â”‚     â”‚ (gemini-1.5-    â”‚
â”‚ are present     â”‚     â”‚                  â”‚     â”‚ flash)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                           â”‚
ğŸ¤– AI PROCESSING LAYER                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ IELTS prompt    â”‚â”€â”€â”€â”€â–¶â”‚ AI request sent  â”‚â”€â”€â”€â”€â–¶â”‚ Gemini analyzes â”‚
â”‚ template filled â”‚     â”‚ with prompt +    â”‚     â”‚ audio against   â”‚
â”‚ with question   â”‚     â”‚ base64 audio     â”‚     â”‚ IELTS criteria  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                           â”‚
                                                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ JSON parsing    â”‚â—€â”€â”€â”€â”€â”‚ Markdown cleanup â”‚â—€â”€â”€â”€â”€â”‚ AI returns      â”‚
â”‚ converts string â”‚     â”‚ removes ```json  â”‚     â”‚ structured JSON â”‚
â”‚ to JavaScript   â”‚     â”‚ code blocks      â”‚     â”‚ with scores     â”‚
â”‚ object          â”‚     â”‚                  â”‚     â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
ğŸ“¤ RESPONSE LAYER                              
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ res.json()      â”‚â”€â”€â”€â”€â–¶â”‚ HTTP response    â”‚â”€â”€â”€â”€â–¶â”‚ Frontend        â”‚
â”‚ sends structuredâ”‚     â”‚ sent back to     â”‚     â”‚ receives data   â”‚
â”‚ IELTS results   â”‚     â”‚ frontend         â”‚     â”‚ via fetch()     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                           â”‚
ğŸ¨ UI RENDERING LAYER                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ setResult(data) â”‚â”€â”€â”€â”€â–¶â”‚ React state      â”‚â”€â”€â”€â”€â–¶â”‚ Component       â”‚
â”‚ updates state   â”‚     â”‚ change triggers  â”‚     â”‚ re-renders with â”‚
â”‚ with AI results â”‚     â”‚ re-render        â”‚     â”‚ results UI      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                           â”‚
                                                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CriteriaCard    â”‚     â”‚ Audio playback   â”‚     â”‚ Overall score   â”‚
â”‚ components      â”‚â”€â”€â”€â”€â–¶â”‚ component shows  â”‚â”€â”€â”€â”€â–¶â”‚ displayed in    â”‚
â”‚ show individual â”‚     â”‚ recorded audio   â”‚     â”‚ prominent card  â”‚
â”‚ IELTS scores    â”‚     â”‚                  â”‚     â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ” Detailed Flow Analysis

### 1. User Interaction & Permission Layer

**Trigger**: User clicks "Start Recording" button
**Process**:
- React component calls `startRecording()` function
- Browser requests microphone permissions via `navigator.mediaDevices.getUserMedia()`
- User grants/denies permission via browser dialog

**Data State Changes**:
```typescript
// Before: Initial state
isRecording: false
audioBlob: null
audioUrl: null

// After permission granted:
isRecording: true
// MediaRecorder instance created and stored in ref
```

**Key Technologies**:
- React useState hooks for state management
- Browser MediaDevices API for hardware access
- Promise-based async/await pattern

---

### 2. Audio Capture & Processing Layer

**Real-time Data Collection**:
```typescript
mediaRecorder.ondataavailable = (event) => {
  if (event.data.size > 0) {
    chunksRef.current.push(event.data) // Accumulate audio chunks
  }
}
```

**Data Transformation on Stop**:
```typescript
mediaRecorder.onstop = () => {
  // Combine all chunks into single Blob
  const audioBlob = new Blob(chunksRef.current, { type: 'audio/webm' })
  
  // Create browser-playable URL
  const audioUrl = URL.createObjectURL(audioBlob)
  
  // Update React state
  setAudioBlob(audioBlob)    // For backend upload
  setAudioUrl(audioUrl)      // For UI audio player
}
```

**Data Flow**:
- Audio streams â†’ MediaRecorder chunks â†’ Blob â†’ Object URL
- Binary audio data preserved throughout pipeline

---

### 3. HTTP Request Layer

**FormData Construction**:
```typescript
const formData = new FormData()
formData.append('audio', audioBlob, 'recording.webm') // Binary file
formData.append('question', question)                 // Text data
```

**Network Request**:
```typescript
const response = await fetch('http://localhost:3002/api/analyze-answer', {
  method: 'POST',
  body: formData,  // Multipart/form-data automatically set
})
```

**Data Transformation**:
- Binary Blob â†’ FormData â†’ HTTP multipart request â†’ Backend reception

---

### 4. Backend Processing Layer

**Middleware Pipeline**:
1. **CORS Middleware**: Validates cross-origin request
2. **Multer Middleware**: Parses multipart data, extracts file
3. **Route Handler**: Processes file and question

**Data Extraction**:
```javascript
// File accessible via Multer
const audioBuffer = req.file.buffer     // Binary audio data
const fileName = req.file.originalname  // 'recording.webm'
const mimeType = req.file.mimetype     // 'audio/webm'

// Question accessible via body parser
const { question } = req.body          // Text string
```

**Base64 Conversion**:
```javascript
const audioBase64 = req.file.buffer.toString('base64')
// Binary â†’ Base64 string for AI API
```

---

### 5. AI Processing Layer

**Request Structure to Gemini**:
```javascript
const result = await model.generateContent([
  prompt,                    // IELTS evaluation instructions
  {
    inlineData: {
      data: audioBase64,      // Base64 encoded audio
      mimeType: 'audio/webm'  // Format specification
    }
  }
])
```

**AI Response Processing**:
```javascript
// Raw response often wrapped in markdown
const text = response.text() // "```json\n{...}\n```"

// Clean markdown formatting
let cleanText = text.replace(/```json\s*/, '').replace(/```\s*$/, '')

// Parse to JavaScript object
const analysisResult = JSON.parse(cleanText)
```

**Data Structure Returned**:
```json
{
  "transcript": "User's spoken words...",
  "score": "6.5",
  "fluency_coherence": {
    "score": "6",
    "strengths": "Good flow and connection...",
    "improvements": "Work on reducing hesitation..."
  },
  "lexical_resource": { "score": "7", ... },
  "grammatical_range": { "score": "6", ... },
  "pronunciation": { "score": "7", ... },
  "overall_assessment": "Strong performance with..."
}
```

---

### 6. Response & UI Rendering Layer

**Backend Response**:
```javascript
res.json(analysisResult) // Send structured JSON to frontend
```

**Frontend State Update**:
```typescript
const data = await response.json()
setResult(data) // Triggers React re-render
```

**UI Component Rendering**:
```typescript
// Conditional rendering based on result state
{result && (
  <div>
    {/* Audio playback component */}
    <audio src={audioUrl} controls />
    
    {/* Score display */}
    <div>Overall Score: {result.score}</div>
    
    {/* Individual criteria cards */}
    {result.fluency_coherence && (
      <CriteriaCard
        title="Fluency & Coherence"
        score={result.fluency_coherence.score}
        strengths={result.fluency_coherence.strengths}
        improvements={result.fluency_coherence.improvements}
      />
    )}
  </div>
)}
```

---

## ğŸš€ Data Flow Optimization Opportunities

### Current Architecture Strengths:
- âœ… Clean separation of concerns
- âœ… Proper error handling at each layer
- âœ… Type safety with TypeScript interfaces
- âœ… Responsive UI with loading states

### Areas for Improvement:
1. **Caching Layer**: Add Redis for frequently requested analyses
2. **File Storage**: Move from memory to persistent storage (S3/Firebase)
3. **Data Validation**: Add schema validation for AI responses
4. **Rate Limiting**: Prevent API abuse and cost control
5. **Offline Support**: Cache results for offline viewing

### Future Data Flow Enhancements:
1. **User Authentication**: Add user sessions and data persistence
2. **Test History**: Store and retrieve past results
3. **Analytics Pipeline**: Track performance trends over time
4. **Real-time Updates**: WebSocket connections for live feedback

---

## ğŸ› ï¸ Technologies & APIs Used

### Frontend Data Flow:
- **React State**: `useState`, `useRef` for component state
- **Browser APIs**: MediaRecorder, getUserMedia, Blob, URL APIs
- **HTTP Client**: Fetch API with FormData for file uploads
- **TypeScript**: Interface definitions for type safety

### Backend Data Flow:
- **Express.js**: Routing and middleware pipeline
- **Multer**: Multipart form data parsing
- **Google Gemini**: AI processing API
- **Node.js**: Buffer handling for binary data

### Data Formats:
- **Audio**: WebM â†’ Base64 â†’ AI Analysis
- **HTTP**: FormData â†’ JSON responses
- **State**: JavaScript objects â†’ React components

---

## ğŸ“Š Performance Metrics

### Current Data Flow Performance:
- **Audio Recording**: Real-time, no noticeable latency
- **File Upload**: ~38KB average, <1 second transfer
- **AI Processing**: 3-8 seconds (depends on audio length)
- **UI Rendering**: Instant (React state updates)

### Bottlenecks Identified:
1. **AI API Latency**: 3-8 seconds for processing
2. **Memory Storage**: Not scalable for multiple users
3. **No Caching**: Repeated requests to AI API

### Optimization Targets:
- Reduce AI processing time through prompt optimization
- Implement result caching for identical audio
- Add background processing for better UX

---

*Last Updated: January 2025*
*This document should be updated as the architecture evolves*